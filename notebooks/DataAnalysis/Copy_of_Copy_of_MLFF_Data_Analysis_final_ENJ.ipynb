{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of MLFF-Data Analysis - final - ENJ.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-fCq3-0rtG_",
        "colab_type": "code",
        "outputId": "b22bc0f1-7073-4e27-a626-261dc4ef0afd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install arch\n",
        "! pip install pyflux\n",
        "import pyflux as pf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting arch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/9e/7628ae53df0494a08d256dcdccc2519aa058c7c7ccb0fc6ca4a380b0bc86/arch-4.11-cp36-cp36m-manylinux1_x86_64.whl (711kB)\n",
            "\r\u001b[K     |▌                               | 10kB 17.4MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█▍                              | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |█▉                              | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |██▎                             | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |██▊                             | 61kB 3.1MB/s eta 0:00:01\r\u001b[K     |███▏                            | 71kB 3.6MB/s eta 0:00:01\r\u001b[K     |███▊                            | 81kB 4.1MB/s eta 0:00:01\r\u001b[K     |████▏                           | 92kB 4.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 133kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 143kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 153kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 163kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 174kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 184kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 194kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 204kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 215kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 225kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 235kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 245kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 256kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 266kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 276kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 286kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 296kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 307kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 317kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 327kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 337kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 348kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 358kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 368kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 378kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 389kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 399kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 409kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 419kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 430kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 440kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 450kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 460kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 471kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 481kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 491kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 501kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 512kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 522kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 532kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 542kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 552kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 563kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 573kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 583kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 593kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 604kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 614kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 624kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 634kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 645kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 655kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 665kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 675kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 686kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 696kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 706kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 716kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from arch) (1.17.5)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.6/dist-packages (from arch) (1.4.1)\n",
            "Requirement already satisfied: statsmodels>=0.9 in /usr/local/lib/python3.6/dist-packages (from arch) (0.10.2)\n",
            "Requirement already satisfied: pandas>=0.22 in /usr/local/lib/python3.6/dist-packages (from arch) (0.25.3)\n",
            "Requirement already satisfied: cython>=0.29 in /usr/local/lib/python3.6/dist-packages (from arch) (0.29.14)\n",
            "Collecting property-cached>=1.6.2\n",
            "  Downloading https://files.pythonhosted.org/packages/c0/11/6e91ff5fe0476492f023cebad434a1a34fc513cfa98ddb1f3e5c856d2d99/property_cached-1.6.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels>=0.9->arch) (0.5.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22->arch) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22->arch) (2.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.0->statsmodels>=0.9->arch) (1.12.0)\n",
            "Installing collected packages: property-cached, arch\n",
            "Successfully installed arch-4.11 property-cached-1.6.3\n",
            "Collecting pyflux\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/e2/ac8ea14d34556e83a9fe9e23ba7b02ca14951849b9637c238ca83d04ac3c/pyflux-0.4.15.tar.gz (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pyflux) (1.17.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pyflux) (0.25.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pyflux) (1.4.1)\n",
            "Collecting numdifftools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/c0/b0d967160ecc8db52ae34e063937d85e8d386f140ad4826aae2086245a5e/numdifftools-0.9.39-py2.py3-none-any.whl (953kB)\n",
            "\u001b[K     |████████████████████████████████| 962kB 24.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: patsy in /usr/local/lib/python3.6/dist-packages (from pyflux) (0.5.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->pyflux) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->pyflux) (2.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy->pyflux) (1.12.0)\n",
            "Building wheels for collected packages: pyflux\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Did64uvdrwf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/vmeylan/machine_learning_for_finance.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp1SVRz1rjrI",
        "colab_type": "text"
      },
      "source": [
        "### Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF1ZIskzro6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('machine_learning_for_finance/data/preprocessed_data/enj.csv').drop(['Unnamed: 0', '_INTERCEPT', '_REALIZED_VOL', '_VOL_PROXY', '_NEGATIVE_RETURNS', '_BTC_REALIZED_VOL', '_BTC_VOL_PROXY','BTC_low', 'BTC_high', 'high', 'low', '_BTC_NEGATIVE_RETURNS', 'time'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nvDO7iurdJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNcrzQFBupDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyuR9JGt38kD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.loc[:,'VOL'] = (data._RETURNS**2).ewm(halflife=10).mean()\n",
        "data.loc[:,'_FROM_EXCHANGE_EWMA'] = (data._FROM_EXCHANGE_TRANSACTIONS**2).ewm(halflife=10).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFRzEuD23HkZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot((data._RETURNS**2).ewm(halflife=10).mean())\n",
        "plt.title('EW volatility vs. number of trading days elapsed of ENJ coin')\n",
        "plt.xticks(ticks = [0,200,400,600,800])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgYSI2lQsOVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.set(style=\"white\")\n",
        "\n",
        "# Compute the correlation matrix\n",
        "corr = data.corr()\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.zeros_like(corr, dtype=np.bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0, vmin=-1,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
        "plt.suptitle('Correlation matrix of the variables, ENJ token')\n",
        "\n",
        "pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtrybRaeYMxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.loc[~data.isna().any(axis=1)] # drop NaN rows"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6IiG_Cr6Kpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data.drop('VOL', axis=1)\n",
        "y = data.VOL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_bKGn6cp6Ful",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33, random_state=2, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bxPHqsqk6FCn"
      },
      "source": [
        "### *) Statistical Significance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CiW3a1Bb5_39",
        "colab": {}
      },
      "source": [
        "# Computation of the F scores for each feature to see which features are statistically significant\n",
        "\n",
        "from sklearn.feature_selection import f_regression\n",
        "\n",
        "p_val = f_regression(X, y)[1]\n",
        "p_val_table = pd.DataFrame({'p_val':p_val,\n",
        "              'column_name': data.drop(['_RETURNS'], axis=1).columns}).sort_values('p_val')\n",
        "display('Statistical significance to predict returns^2')\n",
        "print(p_val_table.to_latex(index=False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NX1LYMn15-gn",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33, random_state=2, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qTSVnQy7K1F",
        "colab_type": "text"
      },
      "source": [
        "There are too many variables for the model to predict correctly with the amount of data (800 observations). This is called overfitting. We will fit simpler models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehhCKDql7KAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "print('R2 for a Linear Regression with one variable only')\n",
        "print('=================================================')\n",
        "def LR_results(variable):\n",
        "\n",
        "  X = (data.loc[:, variable].values.reshape(-1,1))\n",
        "\n",
        "  reg = LinearRegression()\n",
        "\n",
        "\n",
        "  reg.fit(X,y)\n",
        "  \n",
        "\n",
        "  return reg.score(X,y)\n",
        "\n",
        "\n",
        "for variable in data.columns:\n",
        "  if variable == 'VOL':\n",
        "    continue\n",
        "  print(' {:.2f} - {}'.format(LR_results(variable), variable))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO8PmARTdXFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame([[0.32, 'BTC_close'],\n",
        " [0.10,'BTC_volume'],\n",
        " [0.00, '_BTC_RETURNS'],\n",
        " [0.00, '_TO_EXCHANGE_TRANSACTIONS'],\n",
        " [0.24, '_FROM_EXCHANGE_TRANSACTIONS'],\n",
        " [0.04, '_ONCHAIN_TRANSACTIONS'],\n",
        " [0.03, '_ONCHAIN_VOLUME'],\n",
        " [0.10 ,'close'],\n",
        " [0.03, 'volume']])\n",
        "print(df.to_latex(index=False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6YnluXU8p1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(data.BTC_close, data.VOL, 'r+')\n",
        "plt.title('VOL vs. BTC_close')\n",
        "plt.figure()\n",
        "plt.plot(data._FROM_EXCHANGE_TRANSACTIONS, data.VOL, 'r+')\n",
        "plt.title('VOL vs. _FROM_EXCHANGE_TRANSACTIONS')\n",
        "plt.xlim((0,1500))\n",
        "pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO8jERyUnsiW",
        "colab_type": "text"
      },
      "source": [
        "### *) Comparison with Volatility arima model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYG_V2s97lCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GY1LNAHQ9TJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.shape, y.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adqKD6gEZIdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r = (data.VOL.shift(1) - data.VOL ) \n",
        "r[0]=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eB-Jb7GYIJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# As the VOL process is clearly integrated we will take the first difference\n",
        "\n",
        "r = data.VOL\n",
        "from statsmodels.graphics.tsaplots import plot_pacf\n",
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "\n",
        "plot_pacf(r, lags=list(range(1,48)))\n",
        "plt.title('Partial Autocorrelation of VOL (starting at 1 lag)')\n",
        "plt.show()\n",
        "plot_acf(r, lags=list(range(1,48)))\n",
        "plt.title('Autocorrelation of VOL (starting at 1 lag)')\n",
        "plt.show()\n",
        "\n",
        "r = (data.VOL.shift(1) - data.VOL ) \n",
        "r[0]=0\n",
        "from statsmodels.graphics.tsaplots import plot_pacf\n",
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "\n",
        "plot_pacf(r, lags=list(range(1,48)))\n",
        "plt.title('Partial Autocorrelation of first difference of VOL (starting at 1 lag)')\n",
        "plt.show()\n",
        "plot_acf(r, lags=list(range(1,48)))\n",
        "plt.title('Autocorrelation of first difference of VOL (starting at 1 lag)')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4whmKfpu65dw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ARIMAX model with the most correlated variables.\n",
        "import  copy\n",
        "data_temp = copy.copy(data)\n",
        "data_temp.loc[:,'_RETURNS_2'] = y**2\n",
        "df = data_temp\n",
        "normalized_df=(df-df.mean())/df.std()\n",
        "model = pf.ARIMAX(data=normalized_df, formula='VOL~1+_TO_EXCHANGE_TRANSACTIONS+_FROM_EXCHANGE_TRANSACTIONS+BTC_close+volume+_BTC_RETURNS',\n",
        "                  ar=1,ma=1,integ=1, family=pf.Normal())\n",
        "x = model.fit(\"MLE\")\n",
        "x.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyuY2LLEEKec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ARIMAX model with the volume.\n",
        "import  copy\n",
        "data_temp = copy.copy(data)\n",
        "data_temp.loc[:,'_RETURNS_2'] = y**2\n",
        "df = data_temp\n",
        "normalized_df=(df-df.mean())/df.std()\n",
        "model = pf.ARIMAX(data=normalized_df, formula='_RETURNS_2~1+volume',\n",
        "                  ar=1, ma=0, family=pf.Normal())\n",
        "x = model.fit(\"MLE\")\n",
        "x.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXKgba9CSGbj",
        "colab_type": "text"
      },
      "source": [
        "### *) Random Forest "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qIqslDTSQEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "rfr = RandomForestRegressor()\n",
        "\n",
        "cv = GridSearchCV(rfr, {'n_estimators': [5, 10, 20, 40, 80],\n",
        "                        'max_depth':[1,2,3,4, 10]})\n",
        "\n",
        "cv.fit(X,y)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAQ88kD5Uoix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('The best Cross validated R2 score is {:.2f}'.format(cv.best_score_))\n",
        "\n",
        "# The random forest overfit the data."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYRkJSOXQ_yf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "rid = Ridge()\n",
        "rid.fit(X, y)\n",
        "print('R^2 train score '+str(rid.score(X,y)))\n",
        "\n",
        "\n",
        "cv = GridSearchCV(rid, {'alpha': np.logspace(-5,5,10)}, cv=3, )\n",
        "\n",
        "cv.fit(X,y)\n",
        "print('The best Cross validated R2 score is {:.2f}'.format(cv.best_score_))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PhsQ-BsQ-8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}